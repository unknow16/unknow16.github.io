---
title: CUDA简介
toc: true
date: 2021-01-11 15:51:51
tags:
categories:
---

CUADA，全称Compute Unified Device Architecture，即统一计算设备架构，是由NVIDIA在2007年推出的通用并行计算架构。

- 它提供了GPU编程的简易接口，基于CUDA编程可以构建基于GPU计算的应用程序。
- 它提供了对其它编程语言的支持，如C/C++，Python，Fortran等语言。
- 它解决的是用更加廉价的设备资源，实现更高效的并行计算。

## CUDA架构
将GPU视作一个数据并行计算设备，操作系统的多任务机制可以同时管理CUDA访问GPU和图形程序的运行库，其计算特性支持利用CUDA直观地编写GPU核心程序

## 编程模型
CUDA程序构架分为两部分：Host和Device。一般而言，Host指的是CPU，Device指的是GPU。在CUDA程序构架中，主程序还是由CPU来执行，而当遇到数据并行处理的部分，CUDA 就会将程序编译成GPU能执行的程序，并传送到GPU。而这个程序在CUDA里称做核（kernel）。CUDA允许程序员定义称为核的C语言函数，从而扩展了C语言，在调用此类函数时，它将由N个不同的CUDA线程并行执行N次，这与普通的C语言函数只执行一次的方式不同。执行核的每个线程都会被分配一个独特的线程ID，可通过内置的threadIdx变量在核中访问此ID。在 CUDA 程序中，主程序在调用任何GPU核之前，必须对核进行执行配置，即确定线程块数和每个线程块中的线程数以及共享内存大小。

在同一个块内的线程可彼此协作，通过一些共享存储器来共享数据，并同步其执行来协调存储器访问。一个块中的所有线程都必须位于同一个GPU处理器核心中。因而，一个处理器核心的有限存储器资源制约了每个块的线程数量。在早期的NVIDIA架构中，一个线程块最多可以包含 512个线程，而在后期出现的一些设备中则最多可支持1024个线程。

一般GPU线程数目是很多的，所以不能把所有的线程都塞到同一个块里。但一个内核可由多个大小相同的线程块同时执行，因而线程总数应等于每个块的线程数乘以块的数量。这些同样维度和大小的块将组织为一个一维或二维线程块网格(Grid)。具体框架如下图所示。



## 参考资料
> - []()
> - []()
