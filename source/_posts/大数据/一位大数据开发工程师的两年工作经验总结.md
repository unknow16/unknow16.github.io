---
title: 一位大数据开发工程师的两年工作经验总结
toc: true
date: 2020-12-14 14:17:41
tags:
categories:
---


今年广州的六月，在经历了大雨的洗礼之后，一切都变得更加明朗起来，新的工作，新的人和事。懒惰让我变得更焦虑，焦虑促使我进步，程序员的焦虑大家应该都有共同的感觉，时代的步伐太快了，在这个环境下的软件开发一定会淘汰掉那些不懂得学习，懒惰的人。

希望跟大家共勉。

今天呢，博主主要回顾这两年来，在大数据行业公司从事大数据类的前端开发的工作。最近刚刚换了一份工作，把我的经验稍作总结分享给大家，有什么建议大家在评论区踊跃。 谢谢。

今天的主题，主要是从大数据开发的角度，到大数据治理的必要性，再到图形化建模的畅想，最后在数据质量的把关，然后到大数据可视化的应用，博主总结两年的见闻，和我学习的成果，也不知理解有无偏差吧，希望大家能给出建议。    

大数据开发，有几个阶段：

1. 数据采集【原始数据】
2. 数据汇聚【经过清洗合并的可用数据】
3. 数据转换和映射【经过分类，提取的专项主题数据】
4. 数据应用 【提供api 智能系统  应用系统等】

## 数据采集

数据采集有线上和线下两种方式，线上一般通过爬虫、通过抓取，或者通过已有应用系统的采集，在这个阶段，我们可以做一个大数据采集平台，依托自动爬虫（使用python或者nodejs制作爬虫软件），ETL工具、或者自定义的抽取转换引擎，从文件中、数据库中、网页中专项爬取数据，如果这一步通过自动化系统来做的话，可以很方便的管理所有的原始数据，并且从数据的开始对数据进行标签采集，可以规范开发人员的工作。并且目标数据源可以更方便的管理。

数据采集的难点在于多数据源，例如mysql、postgresql、sqlserver 、 mongodb 、sqllite。还有本地文件、excel统计文档、甚至是doc文件。如何将他们规整的、有方案的整理进我们的大数据流程中也是必不可缺的一环。

## 数据汇聚

数据的汇聚是大数据流程最关键的一步，你可以在这里加上数据标准化，你也可以在这里做数据清洗，数据合并，还可以在这一步将数据存档，将确认可用的数据经过可监控的流程进行整理归类，这里产出的所有数据就是整个公司的数据资产了，到了一定的量就是一笔固定资产。

数据汇聚的难点在于如何标准化数据，例如表名标准化，表的标签分类，表的用途，数据的量，是否有数据增量？，数据是否可用？ 需要在业务上下很大的功夫，必要时还要引入智能化处理，例如根据内容训练结果自动打标签，自动分配推荐表名、表字段名等。还有如何从原始数据中导入数据等。

## 数据转换和映射

经过数据汇聚的数据资产如何提供给具体的使用方使用？在这一步，主要就是考虑数据如何应用，如何将两个？三个？数据表转换成一张能够提供服务的数据。然后定期更新增量。

经过前面的那几步，在这一步难点并不太多了，如何转换数据与如何清洗数据、标准数据无二，将两个字段的值转换成一个字段，或者根据多个可用表统计出一张图表数据等等。

## 数据应用

数据的应用方式很多，有对外的、有对内的，如果拥有了前期的大量数据资产，通过restful API提供给用户？或者提供流式引擎 KAFKA 给应用消费? 或者直接组成专题数据，供自己的应用查询？这里对数据资产的要求比较高，所以前期的工作做好了，这里的自由度很高。

## 总结

1. 大数据开发的难点

大数据开发的难点主要是监控，怎么样规划开发人员的工作？开发人员随随便便采集了一堆垃圾数据，并且直连数据库。 短期来看，这些问题比较小，可以矫正。 但是在资产的量不断增加的时候，这就是一颗定时炸弹，随时会引爆，然后引发一系列对数据资产的影响，例如数据混乱带来的就是数据资产的价值下降，客户信任度变低。

2. 如何监控开发人员的开发流程？

答案只能是自动化平台，只有自动化平台能够做到让开发人员感到舒心的同时，接受新的事务，抛弃手动时代。

这就是前端开发工程师在大数据行业中所占有的优势点，如何制作交互良好的可视化操作界面？如何将现有的工作流程、工作需求变成一个个的可视化操作界面？ 可不可以使用智能化取代一些无脑的操作？

从一定意义上来说，大数据开发中，我个人认为前端开发工程师占据着更重要的位置，仅次于大数据开发工程师。至于后台开发，系统开发是第三位的。好的交互至关重要，如何转换数据，如何抽取数据，一定程度上，都是有先人踩过的坑，例如kettle，再例如kafka，pipeline ，解决方案众多。关键是如何交互？ 怎么样变现为可视化界面？ 这是一个重要的课题。

现有的各位朋友的侧重点不同，认为前端的角色都是可有可无，我觉得是错误的，后台的确很重要，但是后台的解决方案多。 前端实际的地位更重要，但是基本无开源的解决方案，如果不够重视前端开发， 面临的问题就是交互很烂，界面烂，体验差，导致开发人员的排斥，而可视化这块的知识点众多，对开发人员的素质要求更高。

## 大数据治理

大数据治理应该贯穿整个大数据开发流程，它有扮演着重要的角色，浅略的介绍几点：

1. 数据血缘
1. 数据质量审查
1. 全平台监控

## 数据血缘
从数据血缘说起，数据血缘应该是大数据治理的入口，通过一张表，能够清晰看见它的来龙去脉，字段的拆分，清洗过程，表的流转，数据的量的变化，都应该从数据血缘出发，我个人认为，大数据治理整个的目标就是这个数据血缘，从数据血缘能够有监控全局的能力。

数据血缘是依托于大数据开发过程的，它包围着整个大数据开发过程，每一步开发的历史，数据导入的历史，都应该有相应的记录，数据血缘在数据资产有一定规模时，基本必不可少。

## 数据质量审查

数据开发中，每一个模型（表）创建的结束，都应该有一个数据质量审查的过程，在体系大的环境中，还应该在关键步骤添加审批，例如在数据转换和映射这一步，涉及到客户的数据提供，应该建立一个完善的数据质量审查制度，帮助企业第一时间发现数据存在的问题，在数据发生问题时也能第一时间看到问题的所在，并从根源解决问题，而不是盲目的通过连接数据库一遍一遍的查询sql。

## 全平台监控

监控呢，其实包含了很多的点，例如应用监控，数据监控，预警系统，工单系统等，对我们接管的每个数据源、数据表都需要做到实时监控，一旦发生殆机，或者发生停电，能够第一时间电话或者短信通知到具体负责人，这里可以借鉴一些自动化运维平台的经验的，监控约等于运维，好的监控提供的数据资产的保护也是很重要的。

## 大数据可视化

大数据可视化不仅仅是图表的展现，大数据可视化不仅仅是图表的展现，大数据可视化不仅仅是图表的展现，重要的事说三遍，大数据可视化归类的数据开发中，有一部分属于应用类，有一部分属于开发类。

在开发中，大数据可视化扮演的是可视化操作的角色， 如何通过可视化的模式建立模型？ 如何通过拖拉拽，或者立体操作来实现数据质量的可操作性？ 画两个表格加几个按钮实现复杂的操作流程是不现实的。

在可视化应用中，更多的也有如何转换数据，如何展示数据，图表是其中的一部分，平时更多的工作还是对数据的分析，怎么样更直观的表达数据？这需要对数据有深刻的理解，对业务有深刻的理解，才能做出合适的可视化应用。

## 智能的可视化平台

可视化是可以被再可视化的，例如superset，通过操作sql实现图表，有一些产品甚至能做到根据数据的内容智能分类，推荐图表类型，实时的进行可视化开发，这样的功能才是可视化现有的发展方向，我们需要大量的可视化内容来对公司发生产出，例如服装行业，销售部门：进货出货，颜色搭配对用户的影响，季节对选择的影响   生产部门：布料价格走势？  产能和效率的数据统计？  等等，每一个部门都可以有一个数据大屏，可以通过平台任意规划自己的大屏，所有人每天能够关注到自己的领域动向，这才是大数据可视化应用的具体意义。

## 写在最后

洋洋洒洒写了很多，对我近两年的所见所闻所学所想进行了一些总结，有些童鞋会问，不是技术么？为什么没有代码？   博主要说，代码博主要学的，要写的，但是与工作无关，代码是我个人的技能，个人傍身，实现个人想法的重要技能。 但是，代码与业务的关系不大，在工作中，懂业务的人代码写的更好，因为他知道公司想要什么。 如果你业务很差，那也没关系，你代码好就行了呀，根据别人的交代干活，也是很不错的。技术和业务是相辅相成的，稍后博主总结代码的精进。

写完了，博主的焦虑一丝未少，我的代码规范性不够，目前技术栈js、java、nodejs、python 。

主业js熟练度80%吧，正在研究阮一峰的es6（看的差不多）和vuejs的源码（有点搁浅），vuejs算是中等，css和布局方面可以说还可以，另外d3.js，go.js都是处于会用，能干活。 nodejs呢，express和koa无问题，看过一些express的源代码，还写过两个中间件。

java、python都处于能做项目的程度，目前也不想抽很多精力去深入它们，就想要保持在想用能用的地步吧。

未来的几年，博主努力工作，多学学人工智能、大数据开发的知识，未来这块应该还有一些热度的吧。

最后，和大家共勉，更希望大家能给一些规划建议，三人行，必有我师焉。


## 参考资料
> - []()
> - []()
